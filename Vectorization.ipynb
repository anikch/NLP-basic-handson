{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vectorization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOD5TYESW8E33oq74o2d154",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anikch/NLP-basic-handson/blob/main/Vectorization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhdB-Co16FzY",
        "outputId": "18764d9c-9655-4dfa-a421-59734dc45f9e"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#nltk.download('punkt')"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FijDIRnt6JoH"
      },
      "source": [
        "1. Write a program to input three sentences from user and creates the corpus\n",
        "Example: Let’s say these 3 are your \n",
        "strings:S1=” India won the match”\n",
        "S2=” England won the cricket match”\n",
        "S3=” Australia won the final match”\n",
        "Then Corpus (list of union of all words from all strings) is: [India, England, Australia, won, the, match, cricket, final]\n",
        "\n",
        "Create a function named “MakeCorpus” which will take list of string as an input and will return a list having union of all words. Save this function in a python file named “Corpus”. This can be used for future applications"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC4h1MKf6IBM"
      },
      "source": [
        "# Creating Corpus Function\n",
        "def MakeCorpus(s1, s2, s3):\n",
        "  s1= re.sub(r'[^a-zA-Z0-9 _-]','', s1.lower())\n",
        "  s2= re.sub(r'[^a-zA-Z0-9 _-]','', s2.lower())\n",
        "  s3= re.sub(r'[^a-zA-Z0-9 _-]','', s3.lower())\n",
        "  s1_tok= set(nltk.word_tokenize(s1))\n",
        "  s2_tok= set(nltk.word_tokenize(s2))\n",
        "  s3_tok= set(nltk.word_tokenize(s3))\n",
        "  s_tok= set.union(s1_tok, s2_tok, s3_tok)\n",
        "  s_tok= [i for i in s_tok if i not in string.punctuation]\n",
        "  return s_tok"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP89R_zi7sUu",
        "outputId": "1158c379-0eb3-4234-9586-8bc64ef49257"
      },
      "source": [
        "# Creating Corpus from user input\n",
        "s1= input('Enter 1st Sentence: ')\n",
        "s2= input('Enter 2nd Sentence: ')\n",
        "s3= input('Enter 3rd Sentence: ')\n",
        "MakeCorpus(s1, s2, s3)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter 1st Sentence: India won the match\n",
            "Enter 2nd Sentence:  England won the cricket match\n",
            "Enter 3rd Sentence:  Australia won the final match\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['england', 'cricket', 'final', 'india', 'the', 'australia', 'match', 'won']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rns1wObM9VAa"
      },
      "source": [
        "2. Write a program to input three sentences from user and convert them into vectors.    Use presence and absence of words to build the vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9iDDtk-BFLp"
      },
      "source": [
        "# Creating function to vectorize based on presence/ absence\n",
        "def PresenceAbsenceVectorization(s1, s2, s3):\n",
        "  corpus= MakeCorpus(s1, s2, s3)\n",
        "  s1_tok= nltk.word_tokenize(s1.lower())\n",
        "  s2_tok= nltk.word_tokenize(s2.lower())\n",
        "  s3_tok= nltk.word_tokenize(s3.lower())\n",
        "  s1_vec= [1 if tok in s1_tok else 0 for tok in corpus]\n",
        "  s2_vec= [1 if tok in s2_tok else 0 for tok in corpus]\n",
        "  s3_vec= [1 if tok in s3_tok else 0 for tok in corpus]\n",
        "  return (s1_vec, s2_vec, s3_vec, corpus)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aUNhQEHFkcK",
        "outputId": "548419a2-3381-427a-feea-358ba9d50ff9"
      },
      "source": [
        "# Creating vectors for user inputs\n",
        "s1= input('Enter 1st Sentence: ')\n",
        "s2= input('Enter 2nd Sentence: ')\n",
        "s3= input('Enter 3rd Sentence: ')\n",
        "(s1_vec, s2_vec, s3_vec, corpus)= PresenceAbsenceVectorization(s1, s2, s3)\n",
        "\n",
        "print('Tokens:', corpus)\n",
        "print('Vector for s1:', s1_vec)\n",
        "print('Vector for s2:', s2_vec)\n",
        "print('Vector for s3:', s3_vec)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter 1st Sentence: India won the match\n",
            "Enter 2nd Sentence: England won the cricket match\n",
            "Enter 3rd Sentence: Australia won the final match\n",
            "Tokens: ['england', 'cricket', 'final', 'india', 'the', 'australia', 'match', 'won']\n",
            "Vector for s1: [0, 0, 0, 1, 1, 0, 1, 1]\n",
            "Vector for s2: [1, 1, 0, 0, 1, 0, 1, 1]\n",
            "Vector for s3: [0, 0, 1, 0, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDIVUX7VBBAx"
      },
      "source": [
        "3. Write a program to enter 3 strings from a user and vectorise them on basis of their counts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_40_NnN7729I"
      },
      "source": [
        "# Creating function to vectorize based on token counts\n",
        "def CountVectorization(s1, s2, s3):\n",
        "  corpus= MakeCorpus(s1, s2, s3)\n",
        "  s1_tok= nltk.word_tokenize(s1.lower())\n",
        "  s2_tok= nltk.word_tokenize(s2.lower())\n",
        "  s3_tok= nltk.word_tokenize(s3.lower())\n",
        "  s1_vec= [s1_tok.count(tok) for tok in corpus]\n",
        "  s2_vec= [s2_tok.count(tok) for tok in corpus]\n",
        "  s3_vec= [s3_tok.count(tok) for tok in corpus]\n",
        "  return (s1_vec, s2_vec, s3_vec, corpus)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3UxlVzz_Bbz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "277651d5-9caa-42e0-a3f3-28999e88b0b7"
      },
      "source": [
        "# Creating vectors for user inputs\n",
        "s1= input('Enter 1st Sentence: ')\n",
        "s2= input('Enter 2nd Sentence: ')\n",
        "s3= input('Enter 3rd Sentence: ')\n",
        "(s1_vec, s2_vec, s3_vec, corpus)= CountVectorization(s1, s2, s3)\n",
        "\n",
        "print('Tokens:', corpus)\n",
        "print('Vector for s1:', s1_vec)\n",
        "print('Vector for s2:', s2_vec)\n",
        "print('Vector for s3:', s3_vec)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter 1st Sentence: A lives with B. A plays with C.\n",
            "Enter 2nd Sentence:  B lives with C. B plays with D\n",
            "Enter 3rd Sentence: C lives with D. C plays with A\n",
            "Tokens: ['plays', 'd', 'b', 'a', 'with', 'lives', 'c']\n",
            "Vector for s1: [1, 0, 0, 2, 2, 1, 1]\n",
            "Vector for s2: [1, 1, 2, 0, 2, 1, 0]\n",
            "Vector for s3: [1, 0, 0, 1, 2, 1, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5_eHUETF6Ng"
      },
      "source": [
        "4. Write a program to input 3 strings but vectorise them using TF-IDF (Term Frequency and Inverse Document Frequency) and print the strings along with the vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrVRhqBoEXqt"
      },
      "source": [
        "# Creating function for TF-IDF vectorization\n",
        "\n",
        "def TFIDFVectorization(s1, s2, s3):\n",
        "  corpus= [s1, s2, s3]\n",
        "  tfidf= TfidfVectorizer()\n",
        "  tfidfvec= tfidf.fit_transform(corpus)\n",
        "  df_tfidfvect= pd.DataFrame(tfidfvec.toarray(), index = ['s1','s2', 's3'], columns= tfidf.get_feature_names())\n",
        "  return df_tfidfvect"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbXnr_KaGBnA",
        "outputId": "336d2f39-b487-48a9-9694-16454dec2d72"
      },
      "source": [
        "# User Inputs\n",
        "s1= input('Enter 1st Sentence: ')\n",
        "s2= input('Enter 2nd Sentence: ')\n",
        "s3= input('Enter 3rd Sentence: ')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter 1st Sentence: India won the match\n",
            "Enter 2nd Sentence: England won the cricket match\n",
            "Enter 3rd Sentence: Australia won the final match\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "3U9CsL4CHZ3U",
        "outputId": "2e77b1f9-41d4-48e6-f7fc-8574ce4a8644"
      },
      "source": [
        "# Tf-Idf vectorization\n",
        "df_tfidfvect= TFIDFVectorization(s1, s2, s3)\n",
        "\n",
        "df_tfidfvect"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>australia</th>\n",
              "      <th>cricket</th>\n",
              "      <th>england</th>\n",
              "      <th>final</th>\n",
              "      <th>india</th>\n",
              "      <th>match</th>\n",
              "      <th>the</th>\n",
              "      <th>won</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>s1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.69903</td>\n",
              "      <td>0.412859</td>\n",
              "      <td>0.412859</td>\n",
              "      <td>0.412859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>s2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.572929</td>\n",
              "      <td>0.572929</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.338381</td>\n",
              "      <td>0.338381</td>\n",
              "      <td>0.338381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>s3</th>\n",
              "      <td>0.572929</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.572929</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.338381</td>\n",
              "      <td>0.338381</td>\n",
              "      <td>0.338381</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    australia   cricket   england  ...     match       the       won\n",
              "s1   0.000000  0.000000  0.000000  ...  0.412859  0.412859  0.412859\n",
              "s2   0.000000  0.572929  0.572929  ...  0.338381  0.338381  0.338381\n",
              "s3   0.572929  0.000000  0.000000  ...  0.338381  0.338381  0.338381\n",
              "\n",
              "[3 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    }
  ]
}